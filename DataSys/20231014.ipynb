{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from sqlparse.tokens import Keyword, DML, DDL, Punctuation, Whitespace, Newline, Name, String, Number, Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fm_sql(file_path:str) -> str:\n",
    "\n",
    "    '''\n",
    "    Get formatted sql from file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    indent_str : str\n",
    "    '''\n",
    "\n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        str_sql = sqlparse.format(content, reindent=True, keyword_case='upper')\n",
    "        str_sql = str_sql.strip(' \\t\\n;')\n",
    "    return str_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = get_fm_sql('tag000001.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"var x varchar(20) EXEC :x := to_char(sysdate, 'YYYYMMDDHH24MISS')\\n\"\n",
      " 'INSERT INTO \"1111111\".TAG_EXECUTETIME(TRAN_ID, TAG_CD, STARTTIME, '\n",
      " 'LOGINUSER)\\n'\n",
      " 'SELECT :x AS A,\\n'\n",
      " '       1234567 AS TAG_CD,\\n'\n",
      " '       SYSDATE AS STARTTIME,\\n'\n",
      " '       USER AS LOGINUSER\\n'\n",
      " 'FROM DUAL\\n'\n",
      " 'COMMIT;\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'SELECT 1234567 AS TAG_CD\\n'\n",
      " 'FROM DUAL;\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'DROP TABLE TAG_2222222_TEMP_00;\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'CREATE TABLE TAG_2222222_TEMP_00 AS\\n'\n",
      " 'SELECT CUST_ID,\\n'\n",
      " '       FLG,\\n'\n",
      " '       CNT,\\n'\n",
      " '       TXN_AMT,\\n'\n",
      " '       MAX_DT\\n'\n",
      " 'FROM\\n'\n",
      " '  (SELECT 1,\\n'\n",
      " '          2,\\n'\n",
      " '          3,\\n'\n",
      " '          4\\n'\n",
      " '   FROM DSSDS.XXXXXXX A,\\n'\n",
      " '        DSDEP.XXXXXXX B)\\n'\n",
      " 'GROUP BY CUST_ID;\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'DROP TABLE TAG_3333333;\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'CREATE TABLE TAG_3333333 AS\\n'\n",
      " 'SELECT CUST_ID,\\n'\n",
      " '       FLG,\\n'\n",
      " '       CNT,\\n'\n",
      " '       TXN_AMT,\\n'\n",
      " '       MAX_DT\\n'\n",
      " 'FROM TAG_4444444 A,\\n'\n",
      " '\\n'\n",
      " '  (SELECT X,\\n'\n",
      " '          Y,\\n'\n",
      " '          Z\\n'\n",
      " '   FROM TAG_5555555) B')\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = sqlparse.parse(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Identifier 'var x' at 0x13E5199E0>\n",
      "<Whitespace ' ' at 0x13E51AD60>\n",
      "<Function 'varcha...' at 0x13E5197B0>\n",
      "<Whitespace ' ' at 0x13E51AFA0>\n",
      "<Keyword 'EXEC' at 0x13E517040>\n",
      "<Newline ' ' at 0x13E51F400>\n",
      "<Newline ' ' at 0x13E51F4C0>\n",
      "<Newline ' ' at 0x13E51F520>\n",
      "<DML 'SELECT' at 0x13E51F580>\n",
      "<Whitespace ' ' at 0x13E51F5E0>\n",
      "<Identifier '123456...' at 0x13E5232E0>\n",
      "<Newline ' ' at 0x13E51F820>\n",
      "<Keyword 'FROM' at 0x13E51F880>\n",
      "<Whitespace ' ' at 0x13E51F8E0>\n",
      "<Identifier 'DUAL' at 0x13E523270>\n",
      "<Punctuation ';' at 0x13E51F9A0>\n",
      "<Newline ' ' at 0x13E51FA60>\n",
      "<Newline ' ' at 0x13E51FAC0>\n",
      "<Newline ' ' at 0x13E51FB20>\n",
      "<DDL 'DROP' at 0x13E51FB80>\n",
      "<Whitespace ' ' at 0x13E51FBE0>\n",
      "<Keyword 'TABLE' at 0x13E51FC40>\n",
      "<Whitespace ' ' at 0x13E51FCA0>\n",
      "<Identifier 'TAG_22...' at 0x13E5193C0>\n",
      "<Punctuation ';' at 0x13E51FE20>\n",
      "<Newline ' ' at 0x13E51A940>\n",
      "<Newline ' ' at 0x13E51A1C0>\n",
      "<Newline ' ' at 0x13E51A220>\n",
      "<DDL 'CREATE' at 0x13E51A520>\n",
      "<Whitespace ' ' at 0x13E51A2E0>\n",
      "<Keyword 'TABLE' at 0x13E51A340>\n",
      "<Whitespace ' ' at 0x13E51ACA0>\n",
      "<Identifier 'TAG_22...' at 0x13E5190B0>\n",
      "<Whitespace ' ' at 0x13E51AB20>\n",
      "<Keyword 'AS' at 0x13E51A8E0>\n",
      "<Newline ' ' at 0x13E51AA00>\n",
      "<DML 'SELECT' at 0x13E51AA60>\n",
      "<Whitespace ' ' at 0x13E51AAC0>\n",
      "<IdentifierList 'CUST_I...' at 0x13E50EAC0>\n",
      "<Newline ' ' at 0x13E4D1820>\n",
      "<Keyword 'FROM' at 0x13E4D1E80>\n",
      "<Newline ' ' at 0x13E4D1E20>\n",
      "<Whitespace ' ' at 0x13E4D1B80>\n",
      "<Whitespace ' ' at 0x13E4D11C0>\n",
      "<Parenthesis '(SELEC...' at 0x13E519350>\n",
      "'--------------root_table start--------------'\n",
      "<Parenthesis '(SELEC...' at 0x13E519350>\n",
      "(SELECT 1,\n",
      "          2,\n",
      "          3,\n",
      "          4\n",
      "   FROM DSSDS.XXXXXXX A,\n",
      "        DSDEP.XXXXXXX B)\n",
      "Parenthesis\n",
      "'--------------L1_token start--------------'\n",
      "(\n",
      "Punctuation\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "SELECT\n",
      "DML\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "1,\n",
      "          2,\n",
      "          3,\n",
      "          4\n",
      "IdentifierList\n",
      "True\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "\n",
      "\n",
      "Newline\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "FROM\n",
      "Keyword\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "DSSDS.XXXXXXX A,\n",
      "        DSDEP.XXXXXXX B\n",
      "IdentifierList\n",
      "True\n",
      "'--------------L2_token start--------------'\n",
      "DSSDS.XXXXXXX A\n",
      "Identifier\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      ",\n",
      "Punctuation\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      "\n",
      "\n",
      "Newline\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L2_token start--------------'\n",
      "DSDEP.XXXXXXX B\n",
      "Identifier\n",
      "*******************\n",
      "'--------------L2_token end--------------'\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      ")\n",
      "Punctuation\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------root_table end--------------'\n",
      "<Newline ' ' at 0x13E514D00>\n",
      "<Keyword 'GROUP ...' at 0x13E5144C0>\n",
      "<Whitespace ' ' at 0x13E514400>\n",
      "<Identifier 'CUST_ID' at 0x13E50EEB0>\n",
      "'--------------root_table start--------------'\n",
      "<Identifier 'CUST_ID' at 0x13E50EEB0>\n",
      "CUST_ID\n",
      "Identifier\n",
      "'--------------L1_token start--------------'\n",
      "CUST_ID\n",
      "Name\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------root_table end--------------'\n",
      "<Punctuation ';' at 0x13E514D60>\n",
      "'inherit'\n",
      "['TAG_2222222_TEMP_00']\n",
      "'root'\n",
      "['DSSDS.XXXXXXX A', 'DSDEP.XXXXXXX B']\n",
      "<Newline ' ' at 0x13E514F40>\n",
      "<Newline ' ' at 0x13E514FA0>\n",
      "<Newline ' ' at 0x13E5148E0>\n",
      "<DDL 'DROP' at 0x13E514940>\n",
      "<Whitespace ' ' at 0x13E5146A0>\n",
      "<Keyword 'TABLE' at 0x13E514820>\n",
      "<Whitespace ' ' at 0x13E51B040>\n",
      "<Identifier 'TAG_33...' at 0x13E521A50>\n",
      "<Punctuation ';' at 0x13E4E7FA0>\n",
      "<Newline ' ' at 0x13E451400>\n",
      "<Newline ' ' at 0x13E451040>\n",
      "<Newline ' ' at 0x13E451460>\n",
      "<DDL 'CREATE' at 0x13E4514C0>\n",
      "<Whitespace ' ' at 0x13E451520>\n",
      "<Keyword 'TABLE' at 0x13E451340>\n",
      "<Whitespace ' ' at 0x13E51FEE0>\n",
      "<Identifier 'TAG_33...' at 0x13E521CF0>\n",
      "<Whitespace ' ' at 0x13E51FFA0>\n",
      "<Keyword 'AS' at 0x13E51FD60>\n",
      "<Newline ' ' at 0x13E51FDC0>\n",
      "<DML 'SELECT' at 0x13E522040>\n",
      "<Whitespace ' ' at 0x13E5220A0>\n",
      "<IdentifierList 'CUST_I...' at 0x13E523510>\n",
      "<Newline ' ' at 0x13E51DE20>\n",
      "<Keyword 'FROM' at 0x13E51DE80>\n",
      "<Whitespace ' ' at 0x13E51DEE0>\n",
      "<IdentifierList 'TAG_44...' at 0x13E523580>\n",
      "'--------------root_table start--------------'\n",
      "<IdentifierList 'TAG_44...' at 0x13E523580>\n",
      "TAG_4444444 A,\n",
      "\n",
      "  (SELECT X,\n",
      "          Y,\n",
      "          Z\n",
      "   FROM TAG_5555555) B\n",
      "IdentifierList\n",
      "'--------------L1_token start--------------'\n",
      "TAG_4444444 A\n",
      "Identifier\n",
      "True\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      ",\n",
      "Punctuation\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "\n",
      "\n",
      "Newline\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "\n",
      "\n",
      "Newline\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      " \n",
      "Whitespace\n",
      "False\n",
      "'--------------L1_token end--------------'\n",
      "'--------------L1_token start--------------'\n",
      "(SELECT X,\n",
      "          Y,\n",
      "          Z\n",
      "   FROM TAG_5555555) B\n",
      "Identifier\n",
      "True\n",
      "'--------------L1_token end--------------'\n",
      "'--------------root_table end--------------'\n",
      "'inherit'\n",
      "['TAG_3333333']\n",
      "'root'\n",
      "[   'TAG_4444444 A',\n",
      "    '(SELECT X,\\n          Y,\\n          Z\\n   FROM TAG_5555555) B']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_table(parse):\n",
    "    '''\n",
    "    Extract table from sqlparse.sql.Statement\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parse : sqlparse.sql.Statement\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    table : list\n",
    "    '''\n",
    "    root_table = []\n",
    "    inherit_table = []\n",
    "    status = False\n",
    "    loop = False\n",
    "    root = False\n",
    "    inherit = False\n",
    "    m = 0\n",
    "\n",
    "\n",
    "    for stmt in parse:\n",
    "\n",
    "        L0_root = False\n",
    "        inherit = False\n",
    "        root_table = []\n",
    "        inherit_table = []\n",
    "\n",
    "        for token in stmt.tokens:\n",
    "\n",
    "            pp.pprint(token)\n",
    "            if token._get_repr_name() == 'Keyword':\n",
    "                if token.value == 'EXEC':\n",
    "                    break\n",
    "                elif token.value == 'FROM':\n",
    "                    L0_root = True\n",
    "                elif token.value == 'TABLE':\n",
    "                    inherit = True\n",
    "            \n",
    "\n",
    "            if inherit:\n",
    "\n",
    "                if L0_root:\n",
    "\n",
    "                    if (token._get_repr_name() in {'Identifier', 'IdentifierList', 'Parenthesis'}):\n",
    "\n",
    "                        pp.pprint('--------------root_table start--------------')\n",
    "                        ### 以下建議抽象化\n",
    "\n",
    "                        L1_root = False\n",
    "                        pp.pprint(token)\n",
    "                        print(token.value)\n",
    "                        print(token._get_repr_name())\n",
    "                        #root_table.append(token.value)\n",
    "\n",
    "                        \n",
    " \n",
    "                        ## if 字串內有from 進迴圈 else 加入root_table\n",
    "                        # 1. 確認長度決定是否進迴圈\n",
    "                        # 2. 抽取Table Name\n",
    "                        # 3. Root False\n",
    "                        for L1_token in token:\n",
    "                            \n",
    "                            pp.pprint('--------------L1_token start--------------')\n",
    "                            print(L1_token.value)\n",
    "                            print(L1_token._get_repr_name())\n",
    "                            print(L1_token.is_group)\n",
    "\n",
    "                            if L1_token._get_repr_name() == 'Identifier':\n",
    "                                root_table.append(L1_token.value)\n",
    "\n",
    "\n",
    "                            if L1_token.value == 'FROM':\n",
    "                                L1_root = True\n",
    "                            \n",
    "                            if L1_root:\n",
    "\n",
    "                                if (L1_token._get_repr_name() in {'Identifier', 'IdentifierList', 'Parenthesis'}):\n",
    "                                    for L2_token in L1_token:\n",
    "\n",
    "                                        if (L2_token._get_repr_name() in {'Identifier', 'IdentifierList', 'Parenthesis'}):\n",
    "\n",
    "                                            root_table.append(L2_token.value)\n",
    "                                        pp.pprint('--------------L2_token start--------------')\n",
    "                                        print(L2_token.value)\n",
    "                                        print(L2_token._get_repr_name())\n",
    "                                        print('*******************')\n",
    "\n",
    "\n",
    "                                        pp.pprint('--------------L2_token end--------------')\n",
    "\n",
    "                            \n",
    "                            pp.pprint('--------------L1_token end--------------')\n",
    "\n",
    "                            #         print(L1_token.value)\n",
    "                            #         print('*******************')\n",
    "                                \n",
    "                            #print(L1_token.value)\n",
    "                            #print(L1_token._get_repr_name())\n",
    "                        pp.pprint('--------------root_table end--------------')\n",
    "                    #table.append(token.value)\n",
    "                    #root = False\n",
    "                \n",
    "                else: \n",
    "\n",
    "                    if (token._get_repr_name() == 'Identifier'):\n",
    "                        if len(inherit_table) == 0:\n",
    "                            inherit_table.append(token.value)\n",
    "\n",
    "        if (len(inherit_table) > 0) and (len(root_table) > 0): \n",
    "            pp.pprint('inherit')\n",
    "            pp.pprint(inherit_table)\n",
    "            pp.pprint('root')\n",
    "            pp.pprint(root_table)\n",
    "    #     print(1)\n",
    "    #     pp.pprint(token._get_repr_name())\n",
    "    #     pp.pprint(token.value)\n",
    "## 單筆僅繼承table的在進行drop\n",
    "extract_table(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "from sqlparse.sql import Parenthesis,Function,Identifier, IdentifierList\n",
    "from sqlparse.tokens import Keyword, Name\n",
    "\n",
    "\n",
    "COLUMN_OPERATIONS={'SELECT','FROM'}\n",
    "FUNCTION_OPERATIONS={'SELECT','DROP','INSERT','UPDATE','CREATE'}\n",
    "RESULT_OPERATIONS = {'UNION', 'INTERSECT', 'EXCEPT', 'SELECT'}\n",
    "ON_KEYWORD = 'ON'\n",
    "PRECEDES_TABLE_NAME = {'FROM', 'JOIN', 'DESC', 'DESCRIBE', 'WITH'}\n",
    "global table_names\n",
    "global column_names\n",
    "global columns_rank\n",
    "global function_names\n",
    "global alias_names\n",
    "table_names = []\n",
    "column_names = []\n",
    "function_names = []\n",
    "alias_names = []\n",
    "columns_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_identifier(token):\n",
    "    return isinstance(token, (IdentifierList, Identifier))\n",
    "\n",
    "\n",
    "def is_identifiers(token):\n",
    "    return isinstance(token, Identifier)\n",
    "\n",
    "\n",
    "def is_identifiersList(token):\n",
    "    return isinstance(token, IdentifierList)\n",
    "\n",
    "\n",
    "def is_Function(token):\n",
    "    return isinstance(token, Function)\n",
    "\n",
    "\n",
    "def is_Parenthesis(token):\n",
    "    return isinstance(token, Parenthesis)\n",
    "\n",
    "\n",
    "def precedes_function_name(token_value):\n",
    "    for keyword in FUNCTION_OPERATIONS:\n",
    "        if keyword in token_value:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得该SQL主要功能函数\n",
    "def get_main_functionsql(statment):\n",
    "    return statment.get_type()\n",
    "\n",
    "# 第一层Identifier\n",
    "def _get_one_Identifier(statment):\n",
    "    idfr_list = []\n",
    "    tokens_list = statment.tokens\n",
    "    for each_token in tokens_list:\n",
    "        if each_token._get_repr_name() == 'Identifier':\n",
    "            idfr_list.append(each_token)\n",
    "    return idfr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 满足库.表形式的identifiers提取即判定为表\n",
    "def get_Identifier_keywords_tables(identifiers):\n",
    "    global table_names\n",
    "    if len(identifiers.tokens) == 3 and identifiers.tokens[1].value == ' ':\n",
    "        a = identifiers.tokens[0].value\n",
    "        return table_names.append(a)\n",
    "    if len(identifiers.tokens) > 1 and identifiers.tokens[1].value == '.':\n",
    "        a = identifiers.tokens[0].value\n",
    "        b = identifiers.tokens[2].value\n",
    "        db_table = (a, b)\n",
    "        full_tree = '{}.{}'.format(a, b)\n",
    "        if len(identifiers.tokens) == 3:\n",
    "            return table_names.append(full_tree)\n",
    "        else:\n",
    "            i = identifiers.tokens[3].value\n",
    "            c = identifiers.tokens[4].value\n",
    "            if i == ' ':\n",
    "                return table_names.append(full_tree)\n",
    "            full_tree = '{}.{}.{}'.format(a, b, c)\n",
    "            return table_names.append(full_tree)\n",
    "    if len(identifiers.tokens) == 1:\n",
    "        a = identifiers.tokens[0].value\n",
    "        return table_names.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precedes_table_name(token_value):\n",
    "    for keyword in PRECEDES_TABLE_NAME:\n",
    "        if keyword in token_value:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提底表表名\n",
    "def _extract_table_from_token(statment):\n",
    "    if not hasattr(statment, 'tokens'):\n",
    "        return\n",
    "    # 可添加多个preceding_token\n",
    "    table_name_preceding_token = False\n",
    "\n",
    "    for item in statment.tokens:\n",
    "        # 除Identifier/IdentifierList以外还有Parenthesis和Function有group，这些需要递归\n",
    "        if item.is_group and not is_identifier(item):\n",
    "            _extract_table_from_token(item)\n",
    "\n",
    "        # 启动函数，依赖PRECEDES_TABLE_NAME，当为指定Keyword时候启发table_name_preceding_token\n",
    "        if item.ttype in Keyword:\n",
    "            # 有关键字的情况下可以判定存在表，那么直接跳到符合的情况下，剩余的token不再判断\n",
    "            if precedes_table_name(item.value.upper()):\n",
    "                table_name_preceding_token = True\n",
    "                continue\n",
    "                # 那么直接跳到符合的情况下，剩余的token不再判断\n",
    "        if not table_name_preceding_token:\n",
    "            continue\n",
    "        # 可能From里面也嵌套查询等外表，那么再次设定为False再判断一次\n",
    "        if item.ttype in Keyword or item.value == ',':\n",
    "            if (is_result_operation(item.value) or\n",
    "                    item.value.upper() == ON_KEYWORD):\n",
    "                table_name_preceding_token = False\n",
    "                continue\n",
    "            # FROM clause is over\n",
    "            break\n",
    "\n",
    "        # 只有identifiers和IdentifierList会有库.表\n",
    "        if isinstance(item, Identifier):\n",
    "            process_identifier(item)\n",
    "\n",
    "        if isinstance(item, IdentifierList):\n",
    "            for token in item.tokens:\n",
    "                if is_identifier(token):\n",
    "                    process_identifier(token)\n",
    "\n",
    "                # 该方法解析IdentifierList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表血缘\n",
    "def blood_table(statment):\n",
    "    if precedes_function_name(get_main_functionsql(statment)):\n",
    "        idfr_list = get_one_Identifier(statment)\n",
    "        get_Identifier_keywords_tables(idfr_list[0])\n",
    "    type_name = get_main_functionsql(statment)\n",
    "    extract_table_from_token(statment)\n",
    "    inherit_table = table_names[0]\n",
    "    root_table = set(table_names[1:])\n",
    "    if get_main_functionsql(statment) != 'SELECT':\n",
    "        table_Bloodcurse = '{}->{}'.format(inherit_table, root_table)\n",
    "        return table_Bloodcurse\n",
    "    else:\n",
    "        table_Bloodcurse = set(table_names)\n",
    "        return table_Bloodcurse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSys-HDTnFZfJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
